id: spotify-tracks-dbt-daily
namespace: spotify-dwh-insights.transformation
description: |
  This flow uses dbt to transform the Spotify tracks data ingested from the Spotify API. 
  The flow first clones the dbt repository from GitHub, then runs dbt commands to build the data models. The transformed data is stored in BigQuery.


tasks:
  - id: dbt
    type: io.kestra.plugin.core.flow.WorkingDirectory
    retry:
      maxAttempt: 3
      interval: PT5M
      type: constant
    tasks:
      - id: clone_repository
        type: io.kestra.plugin.git.Clone
        url: https://github.com/jesusoviedo/spotify-dwh-insights
        branch: main 

      - id: dbt_build
        type: io.kestra.plugin.dbt.cli.DbtCLI
        taskRunner:
          type: io.kestra.plugin.scripts.runner.docker.Docker
          delete: true
        containerImage: ghcr.io/kestra-io/dbt-bigquery:latest
        storeManifest:
          key: manifest.json
          namespace: "{{ flow.namespace }}"
        projectDir: dbt/musics_data_modeling
        commands:
          - dbt debug --project-dir dbt/musics_data_modeling
          - dbt deps --project-dir dbt/musics_data_modeling
          - dbt build --project-dir dbt/musics_data_modeling
        inputFiles:
          sa.json: "{{ secret('GCP_CREDENTIALS') }}"
        profiles: |
          musics_data_modeling:
            outputs:
              dev:
                type: bigquery
                dataset: "{{kv('DATASET_NAME_DBT')}}"
                project: "{{ secret('PROJECT_ID') }}"
                location: "{{kv('LOCATION')}}"
                keyfile: sa.json
                method: service-account
                priority: interactive
                threads: 3
                job_execution_timeout_seconds: 300
                job_retries: 1
            target: dev


triggers:
  - id: twice_daily_run
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "0 8,20 * * *"
    timezone: "America/Asuncion"
    description: "Trigger that runs twice a day at 8 AM and 8 PM"
