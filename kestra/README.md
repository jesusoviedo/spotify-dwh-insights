#  Orquestaci贸n con Kestra (`kestra/`)

Este proyecto utiliza **Kestra** para la orquestaci贸n de tareas y flujos. A continuaci贸n, se describe c贸mo configurar y ejecutar el entorno localmente utilizando **Docker Compose** junto con **Docker** para levantar Kestra.

## Configuraci贸n inicial

### 1. Crear la carpeta para los flujos de Kestra
Si no tienes una carpeta `flows` en el directorio de trabajo, debes crearla para almacenar los flujos de Kestra.

```bash
mkdir flows
```


### 2. Establecer las variables de entorno
Es necesario establecer las siguientes variables de entorno para la conexi贸n con la base de datos PostgreSQL utilizada por Kestra. Aseg煤rate de reemplazar los valores de las variables por aquellos que deseas utilizar en tu entorno.

```bash
export POSTGRES_DB="<nombre_de_tu_base_de_datos>"
export POSTGRES_USER="<usuario_de_postgresql>"
export POSTGRES_PASSWORD="<contrase帽a_de_postgresql>"
```

Puedes agregar estas variables a tu archivo `~/.bashrc` o ejecutarlas directamente en tu terminal.

Para verificar que las variables de entorno se han configurado correctamente, puedes ejecutar los siguientes comandos:

```bash
echo $POSTGRES_DB
echo $POSTGRES_USER
echo $POSTGRES_PASSWORD
```

### 3. Agregar secrets de manera manual con codificaci贸n en Base64
Si necesitas almacenar credenciales o claves de acceso de forma segura en Kestra, puedes codificarlas en Base64 antes de agregarlas a los secrets. Esto evita exponer informaci贸n sensible en archivos de configuraci贸n o c贸digo.

#### **Paso 1: Codificar el archivo o clave en Base64**
Si tienes un archivo JSON con credenciales (por ejemplo, `gcs-storage-key.json`), puedes codificarlo en Base64 con:

```bash
base64 gcs-storage-key.json
```

Si en lugar de un archivo quieres codificar un valor de texto, usa
```bash
echo -n "mi_valor_secreto" | base64
```
Esto generar谩 una cadena codificada en Base64.

#### **Paso 2: Agregar el secreto a Kestra**
Existen dos maneras recomendadas de agregar el secreto a Kestra:

**1. A trav茅s del archivo de configuraci贸n de Kestra**

Copia el valor codificado y agr茅galo directamente al archivo de configuraci贸n de Kestra en la secci贸n de secrets.

**2. Mediante variables de entorno en Docker Compose**

Una alternativa m谩s flexible es definir los secrets como variables de entorno y hacer referencia a ellos en el archivo `docker-compose.yml`.

Para nuestro caso, podemos definir las siguientes variables en la terminal:

```bash
export SECRET_CLIENTE_ID="$(echo -n "<cliente_id>" | base64)"
export SECRET_CLIENTE_SECRET="$(echo -n "<cliente_secret>" | base64)"
export SECRET_GCP_CREDENTIALS="$(base64 gcs-storage-key.json)"  
```

Luego, en el `docker-compose.yml`, se pueden referenciar de esta manera:

```bash
environment:
  CLIENTE_ID: ${SECRET_CLIENTE_ID}  
  CLIENTE_SECRET: ${SECRET_CLIENTE_SECRET} 
  GOOGLE_APPLICATION_CREDENTIALS: ${SECRET_GCP_CREDENTIALS}
```

Esto garantiza que los secrets se mantengan fuera del c贸digo y se administren de manera m谩s segura dentro del entorno de ejecuci贸n.

### 4. Iniciar los servicios
Una vez que las variables de entorno y secrets est茅n configuradas, puedes iniciar los servicios utilizando Docker Compose. Esto levantar谩 los contenedores necesarios para ejecutar Kestra y la base de datos PostgreSQL.

```bash
docker compose up
```

Este comando descargar谩 las im谩genes de Docker (si no est谩n disponibles) y pondr谩 en marcha todos los servicios configurados en el archivo `docker-compose.yml`.


### 4. Detener los servicios
Para detener los servicios, puedes usar el siguiente comando:

```bash
docker-compose down
```

Este comando detendr谩 y eliminar谩 los contenedores creados por Docker Compose.


## Soluci贸n de problemas
Si encuentras problemas al ejecutar los servicios, revisa los logs de Docker para identificar cualquier error en la configuraci贸n o en el inicio de los contenedo

```bash
docker-compose logs
```

## Flow de Kestra

En esta secci贸n se explica el prop贸sito de cada flujo de Kestra presente en este proyecto:

### Flow `ingestion_spotify-api-tracks-bigquery-daily.yaml`

#### **Descripci贸n:**
Este flujo en Kestra se encarga de extraer datos desde la API de Spotify y almacenarlos en Google Cloud Storage (GCS). Utiliza un contenedor de Docker con la imagen `rj24/spotify-pipeline` para ejecutar el script `spotify_data_pipeline.py`, que se encuentra dentro del contenedor.

#### **Prop贸sito:**
- Conectar con la API de Spotify utilizando credenciales almacenadas en secrets.
- Extraer datos sobre 谩lbumes recientes de determinados artistas.
- Guardar la informaci贸n en el Data Lake (GCS) dentro del bucket definido en la variable `BUCKET_NAME`.
- Organizar los datos dentro del dataset de BigQuery especificado en `DATASET_NAME`.

#### **Frecuencia de ejecuci贸n:**
- Este flujo se ejecuta autom谩ticamente todos los d铆as a las 6:00 AM (UTC) gracias a un trigger basado en cron (`"0 6 * * *"`).
- En caso de fallo, Kestra intentar谩 reintentar la ejecuci贸n hasta 3 veces, con un intervalo de espera de 5 minutos entre cada intento (`retry.maxAttempt: 3`, `retry.delay: PT5M`).
- Esto garantiza una mayor resiliencia, reduciendo el impacto de posibles fallos temporales en la API de Spotify o en la infraestructura de procesamiento.

#### **Funcionamiento del c贸digo:**
- La tarea principal (`elt_api_spotify_tracks`) se ejecuta dentro de un contenedor de Docker y usa Kestra para gestionar la orquestaci贸n.
- Se utilizan variables de entorno (`CLIENTE_ID`, `CLIENTE_SECRET`, `GOOGLE_APPLICATION_CREDENTIALS`) para autenticarse en la API de Spotify y en GCP.
- El script `spotify_data_pipeline.py` es el encargado del procesamiento de datos y est谩 dentro de la imagen de Docker.

 Para conocer m谩s sobre c贸mo se extraen y procesan los datos dentro del contenedor, se debe revisar la carpeta  [`dlt`](../dlt/), ya que all铆 se encuentra la l贸gica del script `spotify_data_pipeline.py`.


